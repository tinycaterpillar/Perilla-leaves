https://dacon.io/competitions/official/236253/overview/description
에 참여했던 코드입니다.

# 모델
하나의 음성 파일에 대해서 다음과 같이 두 종류의 feature를 뽑아내는 전처리를 진행합니다.
1. 공간 feature(mel spectogram)
2. 시간 feature(pitch, spectral roll-off 등등)

모델은 위 feature를 받고(input) 음성파일에 (가짜 목소리가 있을 확률, 진짜 목소리가 있을 확률)을 내놓습니다(ouput).

모델에서 (1)과 관련된 feature는 CNN을 통해, (2)와 관련된 feature는 RNN을 통해 학습합니다.
(1)과 (2)의 feature vector를 이어붙이고(concate) 이를 분류기(MLP)에 넣어 최종 결과를 내놓습니다.

# 후기
대회의 성적이 너무 아쉬웠는데요, 정말 터무니 없는 성적을 내놓아서 이곳에 적기 부끄럽네요...

만약에 다음 대회를 나가게 된다면 다음을 보완해서 나가려고 합니다.
1. 학습을 원활하게 진행할 수 있는 서버를 확보해놓기.
이 대회를 위해 학교의 서버를 빌려서 사용했습니다(https://aix.inha.ac.kr/). 대회 기간의 대부분을 음성데이터를 공부하고 모델을 구현하는데 다 써버렸습니다. 마지막 1주일을 앞두고는 다들 서버를 빌리려 하였기 때문에 쓸 수 있는 gpu가 거의 없어서 애를 먹었습니다. 결국에는 코렙을 결제해서 서버랑 병행하여 사용했네요.

2. 빠르게 구현할 수 있는 모델부터 실험한다.
결국 성능을 보니, 그렇게 복잡한 모델을 써야했나 싶습니다. 시간에 쫒겨서 가장 처음 생각한 모델을 겨우 학습시켜서 1회 제출밖에 못해봤습니다. 그마저도 준비한 데이터(7만개) 중에 2만개만 사용했습니다
데이터에서 노이즈를 제거하고 두 목소리 음성파일을 합성하는데 많은 공을 들였는데 학습시킬 수 있는 서버와 시간이 부족해서 너무 안타까웠습니다. 

3. 데이터 전처리를 빠르게 할 수 있는 방안을 고안한다.
데이터 전처리가 시간이 부족했던 가장 큰 요인이었습니다. cpu로 전처리를 하는데 너무 시간이 오래걸려서(5만개를 전처리하는데 6시간이나 걸리더라구요) 일주일 동안 학습을 1회밖에 못했습니다. 대안으로 멀티프로세싱을 구현하였으나 공용으로 사용하는 서버이기에 실제로 활용하지는 못했습니다.(사실 돌리다가 서버 관리자님께서 제 ssh연결을 끊어버리셨습니다. 그리고 서버의 코어를 많이 사용하지 말라는 이메일을 보내시더라요. 저 때문에 피해본 다른 분이 없으셨으면 좋겠네요...). 좀 더 찾아보니 gpu를 활용할 수 있는 library가 있긴 했는데 이를 알았을 때는 너무 늦은 상태였습니다.

4. CLI 환경 세팅을 공부한다. (도커를 이용하였더라면...)
서버에서 CLI 세팅을 하여 편하게 background로 학습을 하고 싶었습니다. 실제로 A100, A6000을 CLI로 돌릴 수 있는 anaconda 환경을 구축하였습니다. 그런데 막상 모델을 돌릴 때쯤 되니 좋은 gpu를 다 빌려가서 사용할 수 없는 상태였습니다. 그래서 A40을 빌려서 어떻게 해보려고 하니, cuda 버젼이 달라서 환경세팅을 다시 해야 하더라구요. 이는 동료 팀원한테 맡겼었는데 실패하여 결국 jupter 환경에서 학습과 추론을 진행했습니다. jupyter는 마우스를 계속 움직여주지 않으면 연결이 끊기는 문제가 있었습니다. 개발자 도구로 마우스 움직이는 코드를 짜도 연결이 끊기는 문제가 해결되지 않아 밤을 새서 학습시켰습니다. 혹시 모를 끊김을 방지하여 중간중간에 저장하는 코드도 구현해야만 했고요. 

5. 멘토님께 빠르고 적극적으로 도움을 요청한다. 
멘토님께 무책임한 질문(어떻게 해야할지 모르겠어요 등등)을 하기 싫었습니다. 그래서 좋은 질문을 하려고 배경 공부를 진행했는데 이 과정이 너무 길었습니다. 다음에 할 때에는 보다 빠르게 도움을 받아봐야겠습니다.

# 배운점
이번 프로젝트에서 다음을 배웠습니다.
1. 데이터 전처리 과정에서 python으로 멀티프로세싱 하는 방법을 익혔습니다.
2. anaconda로 CLI 환경을 구축해보았습니다.
3. GPU를 여러개를 빌려 data parallelism을 적용해 모델을 학습해 보았습니다. 하지만 눈에 띄는 속도 변화는 없었는데요, pack_seqence 함수를 적용하기 위해 데이터를 cuda에서 cpu로 옮기는 과정에서 손해를 많이 봐서 그런것으로 추정하고 있습니다.
5. ssh를 통해 리눅스 환경의 원격 서버를 제어해 보았습니다.
4. 음성 데이터에서 사용하는 다양한 feature에 대해 공부해봤습니다.
5. memory profiler를 활용해 보았습니다. colab에서 학습시킬때 학습을 진행할수록 실시간 RAM 사용량이 12GB를 초과하여 연결이 끊겼습니다. memory profiler를 활용하여 메모리 사용량이 많은 부분을 찾아서 안쓰는 메모리를 해제하고 garbage collactor를 호출하는 방식으로 문제를 해결했습니다. (근데 찾은 del 사용과 gc 호출로 인해 안그래도 느리던 전처리 속도가 더 느려졌습니다...ㅜ)

# 감사인사
대회가 막 끝났을 때에는 밤샘에 지치고 하루종일 코딩한 나날이 스치며 너무 분했습니다. 시간이 흐른뒤 제가 얼마나 좋은 환경에 있었는지를 깨닿게 되네요.
1. 엄청 비싼 gpu를 사용할 수 있게 기회를 주신 인하대학교 인공지능 융합센터과 소프트웨어 중심대학 사업단에 감사드립니다.
2. 우리 팀에 많은 열정과 관심을 쏟아주심 김은하 멘토님께 감사드립니다.
