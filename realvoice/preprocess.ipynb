{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUNQPNJF</td>\n",
       "      <td>./train/RUNQPNJF.ogg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JFAWUOGJ</td>\n",
       "      <td>./train/JFAWUOGJ.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RDKEKEVX</td>\n",
       "      <td>./train/RDKEKEVX.ogg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                  path label\n",
       "0  RUNQPNJF  ./train/RUNQPNJF.ogg  real\n",
       "1  JFAWUOGJ  ./train/JFAWUOGJ.ogg  fake\n",
       "2  RDKEKEVX  ./train/RDKEKEVX.ogg  real"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = \"../train.csv\"\n",
    "\n",
    "whole_df = pd.read_csv(train_file)\n",
    "whole_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 음성 길이 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in tqdm(df.iterrows()):\n",
    "#     path = row['path']\n",
    "        \n",
    "#     audio = AudioSegment.from_file(path)\n",
    "#     # 길이 계산 (밀리초 단위)\n",
    "#     length_in_milliseconds = len(audio)\n",
    "\n",
    "#     whole_df.at[index, 'len'] = length_in_milliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "# whole_df.to_csv(\"train_with_length.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 길이가 1000ms 미만인 파일들은 too_short으로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4162, 4)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_df = pd.read_csv(\"train_ver1.csv\")\n",
    "count_len_5000_or_less = whole_df[whole_df['len'] < 1000]\n",
    "count_len_5000_or_less.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "55438it [00:03, 18111.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# 대상 디렉토리 경로\n",
    "destination_dir = './too_short'\n",
    "\n",
    "for index, row in tqdm(whole_df.iterrows()):\n",
    "    if row['len'] >= 1000: continue\n",
    "    \n",
    "    path = row['path']\n",
    "    new_path = path.replace(\"train\", \"too_short\")\n",
    "    whole_df.at[index, 'path'] = new_path\n",
    "    shutil.move(path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "# whole_df.to_csv(\"train_ver2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train data, validation data 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (55438, 4)\n",
      "after: (51276, 4)\n"
     ]
    }
   ],
   "source": [
    "file_path = 'train_ver2.csv'\n",
    "whole_df = pd.read_csv(file_path)\n",
    "print(f\"before: {whole_df.shape}\")\n",
    "filtered_df = whole_df[~whole_df['path'].str.contains('too_short')]\n",
    "print(f\"after: {filtered_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습용 데이터 개수: 41020\n",
      "테스트용 데이터 개수: 10256\n",
      "\n",
      "학습용 데이터의 레이블 비율:\n",
      "real    0.535446\n",
      "fake    0.464554\n",
      "Name: label, dtype: float64\n",
      "\n",
      "테스트용 데이터의 레이블 비율:\n",
      "real    0.535394\n",
      "fake    0.464606\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(filtered_df, test_size=0.2, random_state=42, stratify=filtered_df['label'])\n",
    "\n",
    "# 결과 출력\n",
    "print(\"학습용 데이터 개수:\", len(train_df))\n",
    "print(\"테스트용 데이터 개수:\", len(test_df))\n",
    "\n",
    "# 레이블 비율 확인\n",
    "print(\"\\n학습용 데이터의 레이블 비율:\")\n",
    "print(train_df['label'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\n테스트용 데이터의 레이블 비율:\")\n",
    "print(test_df['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train 폴더에서 validate 폴더로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10256it [00:59, 171.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# 대상 디렉토리 경로\n",
    "destination_dir = './validate'\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows()):\n",
    "    path = row['path']\n",
    "    new_path = path.replace(\"train\", \"validate\")\n",
    "    whole_df.loc[whole_df['id'] == row['id'], 'path'] = new_path\n",
    "    shutil.move(path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "# whole_df.to_csv(\"train_ver3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label 2개로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUNQPNJF</td>\n",
       "      <td>./train/RUNQPNJF.ogg</td>\n",
       "      <td>real</td>\n",
       "      <td>2393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JFAWUOGJ</td>\n",
       "      <td>./train/JFAWUOGJ.ogg</td>\n",
       "      <td>fake</td>\n",
       "      <td>1264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RDKEKEVX</td>\n",
       "      <td>./train/RDKEKEVX.ogg</td>\n",
       "      <td>real</td>\n",
       "      <td>6144.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                  path label     len\n",
       "0  RUNQPNJF  ./train/RUNQPNJF.ogg  real  2393.0\n",
       "1  JFAWUOGJ  ./train/JFAWUOGJ.ogg  fake  1264.0\n",
       "2  RDKEKEVX  ./train/RDKEKEVX.ogg  real  6144.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'train_ver3.csv'\n",
    "whole_df = pd.read_csv(file_path)\n",
    "whole_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUNQPNJF</td>\n",
       "      <td>./train/RUNQPNJF.ogg</td>\n",
       "      <td>real</td>\n",
       "      <td>real</td>\n",
       "      <td>2393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JFAWUOGJ</td>\n",
       "      <td>./train/JFAWUOGJ.ogg</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>1264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RDKEKEVX</td>\n",
       "      <td>./train/RDKEKEVX.ogg</td>\n",
       "      <td>real</td>\n",
       "      <td>real</td>\n",
       "      <td>6144.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                  path label1 label2     len\n",
       "0  RUNQPNJF  ./train/RUNQPNJF.ogg   real   real  2393.0\n",
       "1  JFAWUOGJ  ./train/JFAWUOGJ.ogg   fake   fake  1264.0\n",
       "2  RDKEKEVX  ./train/RDKEKEVX.ogg   real   real  6144.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'label' 칼럼의 이름을 'label1'로 변경\n",
    "whole_df.rename(columns={'label': 'label1'}, inplace=True)\n",
    "whole_df['label2'] = whole_df['label1']\n",
    "\n",
    "# 새로운 칼럼 순서 지정\n",
    "new_column_order = ['id', 'path', 'label1', 'label2', 'len']\n",
    "\n",
    "# 칼럼 순서를 변경한 DataFrame 생성\n",
    "whole_df = whole_df[new_column_order]\n",
    "\n",
    "whole_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "# whole_df.to_csv(\"train_ver4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# two voice랑 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'path', 'label1', 'label2', 'len'], dtype='object') whole_df: (55438, 5)\n",
      "Index(['id', 'path', 'label1', 'label2', 'len'], dtype='object') whole_df: (10000, 5)\n",
      "Index(['id', 'path', 'label1', 'label2', 'len'], dtype='object') whole_df: (10000, 5)\n"
     ]
    }
   ],
   "source": [
    "file_path1 = 'train_ver4.csv'\n",
    "whole_df1 = pd.read_csv(file_path1)\n",
    "print(whole_df1.columns, f\"whole_df: {whole_df1.shape}\")\n",
    "\n",
    "file_path2 = 'train_two_voice.csv'\n",
    "whole_df2 = pd.read_csv(file_path2)\n",
    "print(whole_df2.columns, f\"whole_df: {whole_df2.shape}\")\n",
    "\n",
    "file_path3 = 'validate_two_voice.csv'\n",
    "whole_df3 = pd.read_csv(file_path3)\n",
    "print(whole_df3.columns, f\"whole_df: {whole_df3.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole_df: (75438, 5)\n"
     ]
    }
   ],
   "source": [
    "whole_df = pd.concat([whole_df1, whole_df2, whole_df3], ignore_index=True)\n",
    "print(f\"whole_df: {whole_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "#whole_df.to_csv(\"train_ver5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise에 label 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABJGMLHQ_MVFYKRHJ.ogg</td>\n",
       "      <td>./noiseMix/ABJGMLHQ_MVFYKRHJ.ogg</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABKEEJML_HAJICFQI.ogg</td>\n",
       "      <td>./noiseMix/ABKEEJML_HAJICFQI.ogg</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABKEEJML_HFRWWACQ.ogg</td>\n",
       "      <td>./noiseMix/ABKEEJML_HFRWWACQ.ogg</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                              path label1 label2   len\n",
       "0  ABJGMLHQ_MVFYKRHJ.ogg  ./noiseMix/ABJGMLHQ_MVFYKRHJ.ogg   fake   fake  5000\n",
       "1  ABKEEJML_HAJICFQI.ogg  ./noiseMix/ABKEEJML_HAJICFQI.ogg   fake   fake  5000\n",
       "2  ABKEEJML_HFRWWACQ.ogg  ./noiseMix/ABKEEJML_HFRWWACQ.ogg   fake   fake  5000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'noiseMix.csv'\n",
    "whole_df = pd.read_csv(file_path)\n",
    "whole_df['label1'] = 'fake'\n",
    "whole_df['label2'] = 'fake'\n",
    "\n",
    "# 새로운 칼럼 순서 지정\n",
    "new_column_order = ['id', 'path', 'label1', 'label2', 'len']\n",
    "\n",
    "# 칼럼 순서를 변경한 DataFrame 생성\n",
    "whole_df = whole_df[new_column_order]\n",
    "whole_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "# whole_df.to_csv(\"noiseMix_labeled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise validation train 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'noiseMix_labeled.csv'\n",
    "whole_df = pd.read_csv(file_path)\n",
    "\n",
    "# 데이터프레임 섞기 (랜덤하게 섞지 않으면 인덱스 기준으로 나뉘기 때문에 데이터가 치우칠 수 있음)\n",
    "df_shuffled = whole_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 4:1 비율로 나누기 (80% 훈련, 20% 테스트)\n",
    "train_size = int(len(whole_df) * 0.8)\n",
    "\n",
    "train_df = df_shuffled.iloc[:train_size]\n",
    "test_df = df_shuffled.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1186it [00:03, 370.75it/s]\n"
     ]
    }
   ],
   "source": [
    "destination_dir = './noiseMix_train'\n",
    "\n",
    "for index, row in tqdm(train_df.iterrows()):\n",
    "    path = row['path']\n",
    "    new_path = path.replace(\"noiseMix\", \"noiseMix_train\")\n",
    "    whole_df.loc[whole_df['id'] == row['id'], 'path'] = new_path\n",
    "    shutil.move(path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "297it [00:00, 450.68it/s]\n"
     ]
    }
   ],
   "source": [
    "destination_dir = './noiseMix_validate'\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows()):\n",
    "    path = row['path']\n",
    "    new_path = path.replace(\"noiseMix\", \"noiseMix_validate\")\n",
    "    whole_df.loc[whole_df['id'] == row['id'], 'path'] = new_path\n",
    "    shutil.move(path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABJGMLHQ_MVFYKRHJ.ogg</td>\n",
       "      <td>./noiseMix_train/ABJGMLHQ_MVFYKRHJ.ogg</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABKEEJML_HAJICFQI.ogg</td>\n",
       "      <td>./noiseMix_validate/ABKEEJML_HAJICFQI.ogg</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABKEEJML_HFRWWACQ.ogg</td>\n",
       "      <td>./noiseMix_train/ABKEEJML_HFRWWACQ.ogg</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       path label1  \\\n",
       "0  ABJGMLHQ_MVFYKRHJ.ogg     ./noiseMix_train/ABJGMLHQ_MVFYKRHJ.ogg   fake   \n",
       "1  ABKEEJML_HAJICFQI.ogg  ./noiseMix_validate/ABKEEJML_HAJICFQI.ogg   fake   \n",
       "2  ABKEEJML_HFRWWACQ.ogg     ./noiseMix_train/ABKEEJML_HFRWWACQ.ogg   fake   \n",
       "\n",
       "  label2   len  \n",
       "0   fake  5000  \n",
       "1   fake  5000  \n",
       "2   fake  5000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "# whole_df.to_csv(\"noiseMix_ver1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise랑 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'path', 'label1', 'label2', 'len'], dtype='object') whole_df: (75438, 5)\n",
      "Index(['id', 'path', 'label1', 'label2', 'len'], dtype='object') whole_df: (1483, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABJGMLHQ_MVFYKRHJ.ogg</td>\n",
       "      <td>./noiseMix_train/ABJGMLHQ_MVFYKRHJ.ogg</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABKEEJML_HAJICFQI.ogg</td>\n",
       "      <td>./noiseMix_validate/ABKEEJML_HAJICFQI.ogg</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABKEEJML_HFRWWACQ.ogg</td>\n",
       "      <td>./noiseMix_train/ABKEEJML_HFRWWACQ.ogg</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       path label1  \\\n",
       "0  ABJGMLHQ_MVFYKRHJ.ogg     ./noiseMix_train/ABJGMLHQ_MVFYKRHJ.ogg   fake   \n",
       "1  ABKEEJML_HAJICFQI.ogg  ./noiseMix_validate/ABKEEJML_HAJICFQI.ogg   fake   \n",
       "2  ABKEEJML_HFRWWACQ.ogg     ./noiseMix_train/ABKEEJML_HFRWWACQ.ogg   fake   \n",
       "\n",
       "  label2   len  \n",
       "0   fake  5000  \n",
       "1   fake  5000  \n",
       "2   fake  5000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path1 = 'train_ver5.csv'\n",
    "whole_df1 = pd.read_csv(file_path1)\n",
    "print(whole_df1.columns, f\"whole_df: {whole_df1.shape}\")\n",
    "\n",
    "file_path2 = 'noiseMix_ver1.csv'\n",
    "whole_df2 = pd.read_csv(file_path2)\n",
    "print(whole_df2.columns, f\"whole_df: {whole_df2.shape}\")\n",
    "whole_df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole_df: (76921, 5)\n"
     ]
    }
   ],
   "source": [
    "whole_df = pd.concat([whole_df1, whole_df2], ignore_index=True)\n",
    "print(f\"whole_df: {whole_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "# whole_df.to_csv(\"train_ver6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train data 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number: 72759\n"
     ]
    }
   ],
   "source": [
    "file_path = 'train_ver6.csv'\n",
    "whole_df = pd.read_csv(file_path)\n",
    "\n",
    "# 'path'에 'too_short'가 포함된 행 제외\n",
    "whole_df = whole_df[~whole_df['path'].str.contains('too_short')].reset_index(drop=True)\n",
    "print(f\"number: {whole_df.shape[0]}\")\n",
    "\n",
    "train_df = whole_df[whole_df['path'].str.contains('train')].reset_index(drop=True)\n",
    "validate_df = whole_df[whole_df['path'].str.contains('validate')].reset_index(drop=True)\n",
    "\n",
    "# StratifiedKFold 객체 생성\n",
    "num_splits = 7\n",
    "skf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# 'label1'과 'label2'의 조합을 기준으로 새로운 컬럼 생성\n",
    "train_df['combined_label'] = train_df['label1'].astype(str) + '_' + train_df['label2'].astype(str)\n",
    "validate_df['combined_label'] = validate_df['label1'].astype(str) + '_' + validate_df['label2'].astype(str)\n",
    "\n",
    "# train_df를 StratifiedKFold로 나누기\n",
    "train_splits = []\n",
    "for _, test_index in skf.split(train_df, train_df['combined_label']):\n",
    "    fold_df = train_df.iloc[test_index].reset_index(drop=True)\n",
    "    train_splits.append(fold_df)\n",
    "\n",
    "# validate_df를 StratifiedKFold로 나누기\n",
    "validate_splits = []\n",
    "for _, test_index in skf.split(validate_df, validate_df['combined_label']):\n",
    "    fold_df = validate_df.iloc[test_index].reset_index(drop=True)\n",
    "    validate_splits.append(fold_df)\n",
    "\n",
    "# 각 fold를 합치기\n",
    "for idx, (train_fold, validate_fold) in enumerate(zip(train_splits, validate_splits), start=1):\n",
    "    combined_df = pd.concat([train_fold, validate_fold], ignore_index=True)\n",
    "    combined_df.to_csv(f\"train_final{idx}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# toy sample 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id                                     path label1  \\\n",
      "62360  XRWNTJVY_QTVBBRRG  ./train_two_voice/XRWNTJVY_QTVBBRRG.ogg   real   \n",
      "48923           SFXBXAWC                     ./train/SFXBXAWC.ogg   fake   \n",
      "15388           EZKOLEHD                     ./train/EZKOLEHD.ogg   real   \n",
      "\n",
      "      label2     len  \n",
      "62360   real  6712.0  \n",
      "48923   fake  1080.0  \n",
      "15388   real  5270.0  \n",
      "                      id                                        path label1  \\\n",
      "68948  ROKAMAMN_LVRQEVVN  ./validate_two_voice/ROKAMAMN_LVRQEVVN.ogg   fake   \n",
      "70061  SZESAGEQ_VSGLVWFP  ./validate_two_voice/SZESAGEQ_VSGLVWFP.ogg   real   \n",
      "70427  UVLUNEQH_FSZDFZCL  ./validate_two_voice/UVLUNEQH_FSZDFZCL.ogg   real   \n",
      "\n",
      "      label2     len  \n",
      "68948   fake  4850.0  \n",
      "70061   real  9323.0  \n",
      "70427   fake  2949.0  \n"
     ]
    }
   ],
   "source": [
    "whole_df = pd.read_csv(\"train_final.csv\")\n",
    "\n",
    "sample_train_df = whole_df[whole_df['path'].str.contains('train')].sample(1000, random_state=42)\n",
    "sample_validate_df = whole_df[whole_df['path'].str.contains('validate')].sample(n=200, random_state=42)\n",
    "print(sample_train_df.head(3))\n",
    "print(sample_validate_df.head(3))\n",
    "sample_whole_df = pd.concat([sample_train_df, sample_validate_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:00, 2316.55it/s]\n",
      "200it [00:00, 2712.89it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(sample_train_df.iterrows()):\n",
    "    path = row['path']\n",
    "    new_path = path.replace(\"train\", \"toy_sample_train\")\n",
    "    sample_whole_df.loc[sample_whole_df['id'] == row['id'], 'path'] = new_path\n",
    "    # shutil.copy(path, new_path)\n",
    "\n",
    "for index, row in tqdm(sample_validate_df.iterrows()):\n",
    "    path = row['path']\n",
    "    new_path = path.replace(\"validate\", \"toy_sample_validate\")\n",
    "    sample_whole_df.loc[sample_whole_df['id'] == row['id'], 'path'] = new_path\n",
    "    # shutil.copy(path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "# sample_whole_df.to_csv(\"toy_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# toy sample의 label을 label1, label2로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_sample.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sample_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_sample.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m sample_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jinik\\miniconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jinik\\miniconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jinik\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jinik\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\jinik\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jinik\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\jinik\\miniconda3\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_sample.csv'"
     ]
    }
   ],
   "source": [
    "sample_df = pd.read_csv(\"train_sample.csv\")\n",
    "sample_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PTAMUHTJ</td>\n",
       "      <td>./train/PTAMUHTJ.ogg</td>\n",
       "      <td>real</td>\n",
       "      <td>real</td>\n",
       "      <td>6481.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JBCXCNQF</td>\n",
       "      <td>./train/JBCXCNQF.ogg</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "      <td>1406.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DYTNYEAK</td>\n",
       "      <td>./train/DYTNYEAK.ogg</td>\n",
       "      <td>real</td>\n",
       "      <td>real</td>\n",
       "      <td>8414.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                  path label1 label2     len\n",
       "0  PTAMUHTJ  ./train/PTAMUHTJ.ogg   real   real  6481.0\n",
       "1  JBCXCNQF  ./train/JBCXCNQF.ogg   fake   fake  1406.0\n",
       "2  DYTNYEAK  ./train/DYTNYEAK.ogg   real   real  8414.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'label' 칼럼의 이름을 'label1'로 변경\n",
    "sample_df.rename(columns={'label': 'label1'}, inplace=True)\n",
    "sample_df['label2'] = sample_df['label1']\n",
    "\n",
    "# 새로운 칼럼 순서 지정\n",
    "new_column_order = ['id', 'path', 'label1', 'label2', 'len']\n",
    "\n",
    "# 칼럼 순서를 변경한 DataFrame 생성\n",
    "sample_df = sample_df[new_column_order]\n",
    "\n",
    "sample_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "# sample_df.to_csv(\"train_sample.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
